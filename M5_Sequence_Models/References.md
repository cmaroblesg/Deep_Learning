#References
## W​eek 1:
* [Minimal character-level language model with a Vanilla Recurrent Neural Network, in Python/numpy](https://gist.github.com/karpathy/d4dee566867f8291f086) (GitHub: karpathy)
* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) (Andrej Karpathy blog, 2015)
* [d​eepjazz](https://github.com/jisungk/deepjazz) (GitHub: jisungk)
* [Learning Jazz Grammars](http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf) (Gillick, Tang & Keller, 2010)
* [A Grammatical Approach to Automatic Improvisation](http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf) (Keller & Morrison, 2007)
* [Surprising Harmonies](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&rep=rep1&type=pdf) (Pachet, 1999)

## W​eek 2:
* [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf) (Bolukbasi, Chang, Zou, Saligrama​ & Kalai, 2016)
* [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)(Pennington, Socher & Manning, 2014)
* [W​oebot](https://woebothealth.com/).

## W​eek 4:
* [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing?) (by DeepLearning.AI)
* [Attention Is All You Need](https://arxiv.org/abs/1706.03762) (Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser​ & Polosukhin, 2017)
