# Neural Networks Basics
## Introduction
Learn to set up a machine learning problem with a neural network mindset. Learn to use vectorization to speed up your models.

## Learning Objectives
* Build a logistic regression model structured as a shallow neural network.
* Build the general architecture of a learning algorithm, including parameter initialization, cost function and gradient calculation, and optimization implementation (gradient descent).
* Implement computationally efficient and highly vectorized versions of models.
* Compute derivatives for logistic regression, using a backpropagation mindset.
* Use Numpy functions and Numpy matrix/vector operations.
* Work with iPython Notebooks.
* Implement vectorization across multiple training examples.

## References
* [Introduction to gradients and automatic differentiation](https://www.tensorflow.org/guide/autodiff) (TensorFlow Documentation)
* [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) (TensorFlow Documentation)

## Coding Assignment
* [Lab: Python Basics with numpy](./codes/Python_Basics_With_Numpy_v3a.ipynb)
* [Lab: Logitic Regressiion with a Neural Network mindset](./codes/Logistic_Regression_with_a_Neural_Network_mindset_v6a.ipynb)
